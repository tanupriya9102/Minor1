{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8d2ac4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\mypython\\lib\\site-packages (4.24.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\mypython\\lib\\site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: requests in c:\\mypython\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\mypython\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\mypython\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\mypython\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\mypython\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\mypython\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: filelock in c:\\mypython\\lib\\site-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\mypython\\lib\\site-packages (from transformers) (1.23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\mypython\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\mypython\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\mypython\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\mypython\\lib\\site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\mypython\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\mypython\\lib\\site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\mypython\\lib\\site-packages (from requests->transformers) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70f43cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f484318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16dc4ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Knowledge</td>\n",
       "      <td>1. List two reference parameters in the setHou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Knowledge</td>\n",
       "      <td>2. Explain briefly the meaning of the followin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Knowledge</td>\n",
       "      <td>3. Label the parts of the diagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Knowledge</td>\n",
       "      <td>4. Based on the above dataType class, list all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Knowledge</td>\n",
       "      <td>5. Define morphology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category                                               text\n",
       "0  Knowledge  1. List two reference parameters in the setHou...\n",
       "1  Knowledge  2. Explain briefly the meaning of the followin...\n",
       "2  Knowledge                  3. Label the parts of the diagram\n",
       "3  Knowledge  4. Based on the above dataType class, list all...\n",
       "4  Knowledge                               5. Define morphology"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = 'datasetminor.csv'\n",
    "df = pd.read_csv(datapath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b10c23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='category'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# labels=[labels[label] for label in df['category']]\n",
    "# print(list)\n",
    "df.groupby(['category']).size().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e3c023c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9954, 1193, 3171, 1103, 1378, 2820,  102,    0,    0]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "example_text = 'Analyze the following situation'\n",
    "bert_input = tokenizer(example_text,padding='max_length', max_length = 10, \n",
    "                       truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "print(bert_input['input_ids'])\n",
    "print(bert_input['token_type_ids'])\n",
    "print(bert_input['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e9aab0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Knowledge': 0, 'Comprehension': 1, 'Application': 2, 'Analysis': 3, 'Synthesis': 4, 'Evauation': 5}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "labels = {'Knowledge':0,\n",
    "          'Comprehension':1,\n",
    "          'Application':2,\n",
    "          'Analysis':3,\n",
    "          'Synthesis':4,\n",
    "          'Evauation':5\n",
    "          \n",
    "          }\n",
    "print(labels)\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.labels = [labels[label] for label in df['category']]\n",
    "        self.texts = [tokenizer(text, padding='max_length', max_length = 512, truncation=True,return_tensors=\"pt\") for text in df['text']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11279a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592 74 75\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(112)\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n",
    "                                     [int(.8*len(df)), int(.9*len(df))])\n",
    "?\n",
    "print(len(df_train),len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "600de36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>Synthesis</td>\n",
       "      <td>15. Compose music for a frog play.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>Application</td>\n",
       "      <td>61. Use the distance travelled and cost of pet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>Analysis</td>\n",
       "      <td>36. Differentiate the passages that attacked a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Synthesis</td>\n",
       "      <td>19. Write about your feelings in relation to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>Synthesis</td>\n",
       "      <td>25. Create an equation to represent the soluti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "555    Synthesis                 15. Compose music for a frog play.\n",
       "401  Application  61. Use the distance travelled and cost of pet...\n",
       "476     Analysis  36. Differentiate the passages that attacked a...\n",
       "105    Synthesis    19. Write about your feelings in relation to...\n",
       "565    Synthesis  25. Create an equation to represent the soluti..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "302d0fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fed5034c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, train_label.long())\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label.long())\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
    "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
    "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
    "                  \n",
    "EPOCHS = 5\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12a4d3a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Evaluation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_data, val_data, learning_rate, epochs)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model, train_data, val_data, learning_rate, epochs):\n\u001b[1;32m----> 6\u001b[0m     train, val \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m, Dataset(val_data)\n\u001b[0;32m      8\u001b[0m     train_dataloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(train, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      9\u001b[0m     val_dataloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(val, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[1;34m(self, df)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, df):\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m [labels[label] \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtexts \u001b[38;5;241m=\u001b[39m [tokenizer(text, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m'\u001b[39m, max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, df):\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m [\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtexts \u001b[38;5;241m=\u001b[39m [tokenizer(text, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m'\u001b[39m, max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Evaluation'"
     ]
    }
   ],
   "source": [
    "\n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d0d2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
